# Notebooks de An√°lise - PetCareAi

Este diret√≥rio cont√©m notebooks Jupyter para an√°lises explorat√≥rias, prototipagem de algoritmos e experimentos de ci√™ncia de dados.

## üìã Estrutura dos Notebooks

### üìä An√°lises Explorat√≥rias
- `01_exploratory_data_analysis.ipynb` - An√°lise inicial dos dados de pets
- `02_data_quality_assessment.ipynb` - Avalia√ß√£o da qualidade dos dados
- `03_statistical_analysis.ipynb` - An√°lises estat√≠sticas descritivas
- `04_correlation_analysis.ipynb` - An√°lises de correla√ß√£o entre vari√°veis

### ü§ñ Machine Learning
- `ml_01_clustering_experiments.ipynb` - Experimentos com algoritmos de clustering
- `ml_02_classification_models.ipynb` - Modelos de classifica√ß√£o para ado√ß√£o
- `ml_03_regression_analysis.ipynb` - An√°lises de regress√£o
- `ml_04_anomaly_detection.ipynb` - Detec√ß√£o de anomalias em dados

### üìà Visualiza√ß√µes
- `viz_01_dashboard_prototypes.ipynb` - Prot√≥tipos de dashboards
- `viz_02_interactive_plots.ipynb` - Gr√°ficos interativos
- `viz_03_geospatial_analysis.ipynb` - An√°lises geoespaciais
- `viz_04_time_series_viz.ipynb` - Visualiza√ß√µes de s√©ries temporais

### üî¨ Experimentos
- `exp_01_feature_engineering.ipynb` - Engenharia de caracter√≠sticas
- `exp_02_model_optimization.ipynb` - Otimiza√ß√£o de modelos
- `exp_03_hyperparameter_tuning.ipynb` - Ajuste de hiperpar√¢metros
- `exp_04_ensemble_methods.ipynb` - M√©todos de ensemble

## üöÄ Como Usar

### Pr√©-requisitos
```bash
pip install jupyter notebook
pip install ipython ipykernel
pip install pandas numpy matplotlib seaborn plotly
```

### Iniciar Jupyter
```bash
jupyter notebook
# ou
jupyter lab
```

### Executar Notebooks
1. Abra o Jupyter no navegador
2. Navegue para o diret√≥rio `notebooks/`
3. Clique no notebook desejado
4. Execute as c√©lulas sequencialmente

## üìù Conven√ß√µes

### Estrutura Padr√£o dos Notebooks
1. **Introdu√ß√£o** - Objetivo e contexto
2. **Imports** - Bibliotecas necess√°rias
3. **Configura√ß√µes** - Setup inicial
4. **Carregamento de Dados** - Importa√ß√£o e prepara√ß√£o
5. **An√°lise/Experimento** - Conte√∫do principal
6. **Resultados** - Conclus√µes e insights
7. **Pr√≥ximos Passos** - Recomenda√ß√µes

### Nomenclatura
- Use prefixos num√©ricos para ordem (`01_`, `02_`, etc.)
- Use nomes descritivos em ingl√™s
- Use underscores para separar palavras
- Inclua categoria quando relevante (`ml_`, `viz_`, `exp_`)

### Boas Pr√°ticas
- Sempre documente o prop√≥sito do notebook
- Use markdown para explicar an√°lises
- Mantenha c√©lulas de c√≥digo organizadas
- Limpe outputs antes de fazer commit
- Inclua vers√£o dos dados utilizados

## üóÇÔ∏è Organiza√ß√£o por Categoria

### `/exploratory/` - An√°lises Explorat√≥rias
Notebooks focados em entender os dados, identificar padr√µes e gerar insights iniciais.

### `/modeling/` - Modelagem
Desenvolvimento e teste de modelos de machine learning.

### `/visualization/` - Visualiza√ß√µes
Cria√ß√£o de gr√°ficos, dashboards e visualiza√ß√µes interativas.

### `/experiments/` - Experimentos
Testes de hip√≥teses, valida√ß√£o de conceitos e prototipagem.

### `/production/` - Produ√ß√£o
Notebooks que geram artefatos para produ√ß√£o (modelos, relat√≥rios, etc.).

## üîß Configura√ß√£o do Ambiente

### Jupyter Extensions Recomendadas
```bash
pip install jupyter_contrib_nbextensions
jupyter contrib nbextension install --user
jupyter nbextension enable --py --sys-prefix widgetsnbextension
```

### Extens√µes √öteis
- **Variable Inspector** - Ver vari√°veis em tempo real
- **Table of Contents** - Navega√ß√£o f√°cil
- **Code Folding** - Organizar c√≥digo
- **ExecuteTime** - Tempo de execu√ß√£o das c√©lulas

## üìä Dados Utilizados

### Fonte Principal
- Banco de dados PostgreSQL via Supabase
- Tabela: `pets_analytics`
- Acesso via: `config/database.py`

### Dados de Exemplo
```python
# Template para carregar dados
import pandas as pd
from config.database import supabase

# Carregar dados
result = supabase.table('pets_analytics').select('*').execute()
df = pd.DataFrame(result.data)
```

### Colunas Principais
- `id` - Identificador √∫nico
- `nome` - Nome do pet
- `tipo_pet` - Tipo (C√£o, Gato, etc.)
- `idade` - Idade em anos
- `peso` - Peso em kg
- `comportamento` - Perfil comportamental
- `score_adocao` - Score de adotabilidade
- `adotado` - Status de ado√ß√£o

## üìà M√©tricas e KPIs

### M√©tricas de Neg√≥cio
- Taxa de ado√ß√£o por tipo de pet
- Tempo m√©dio para ado√ß√£o
- Score de adotabilidade m√©dio
- Distribui√ß√£o geogr√°fica

### M√©tricas de Modelo
- Acur√°cia, Precis√£o, Recall
- R¬≤ para regress√µes
- Silhouette Score para clustering
- AUC-ROC para classifica√ß√£o

## üîÑ Workflow de Desenvolvimento

### 1. Explora√ß√£o
- Carregue e explore os dados
- Identifique padr√µes e anomalias
- Documente insights

### 2. Prototipagem
- Teste algoritmos rapidamente
- Valide hip√≥teses
- Experimente com par√¢metros

### 3. Desenvolvimento
- Implemente solu√ß√µes robustas
- Otimize performance
- Documente metodologia

### 4. Valida√ß√£o
- Teste com dados novos
- Valide resultados
- Compare com baseline

### 5. Produ√ß√£o
- Exporte modelos
- Gere c√≥digo de produ√ß√£o
- Documente para deploy

## üîç Exemplos de An√°lises

### An√°lise de Clustering
```python
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Preparar dados
features = ['idade', 'peso', 'sociabilidade', 'energia']
X = df[features].fillna(df[features].mean())

# Normalizar
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Clustering
kmeans = KMeans(n_clusters=4, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

# Visualizar
import plotly.express as px
fig = px.scatter(df, x='idade', y='peso', color=clusters)
fig.show()
```

### An√°lise Preditiva
```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# Preparar dados
X = df[features]
y = df['adotado']

# Dividir dados
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Treinar modelo
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Avaliar
accuracy = rf.score(X_test, y_test)
print(f"Acur√°cia: {accuracy:.3f}")
```

## üìö Recursos √öteis

### Documenta√ß√£o
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Plotly Documentation](https://plotly.com/python/)
- [Jupyter Documentation](https://jupyter.org/documentation)

### Tutorials
- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)
- [Kaggle Learn](https://www.kaggle.com/learn)
- [Towards Data Science](https://towardsdatascience.com/)

## ü§ù Contribuindo

### Adicionando Novos Notebooks
1. Use template padr√£o
2. Documente objetivo claramente
3. Inclua c√©lulas de setup
4. Teste completamente
5. Limpe outputs antes do commit

### Review de Notebooks
- Verifique se executa do in√≠cio ao fim
- Confirme se dados est√£o acess√≠veis
- Valide resultados e conclus√µes
- Aprove documenta√ß√£o

---

Para d√∫vidas ou sugest√µes sobre os notebooks, abra uma issue ou entre em contato com a equipe de Data Science.
